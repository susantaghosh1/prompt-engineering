import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
import optuna
from sklearn.metrics import f1_score
import joblib

# 1. Neural Network Model (Dynamic Architecture)
class BinaryClassifier(nn.Module):
    def __init__(self, input_dim, layer_sizes, dropout_rate):
        super(BinaryClassifier, self).__init__()
        layers = []
        prev_size = input_dim
        
        for size in layer_sizes:
            layers.append(nn.Linear(prev_size, size))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(dropout_rate))
            prev_size = size
        
        layers.append(nn.Linear(prev_size, 1))
        self.network = nn.Sequential(*layers)
    
    def forward(self, x):
        return self.network(x)

# 2. Custom Dataset
class CustomDataset(Dataset):
    def __init__(self, data, labels=None):
        self.data = torch.FloatTensor(data)
        self.labels = torch.FloatTensor(labels).view(-1, 1) if labels is not None else None
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        if self.labels is not None:
            return self.data[idx], self.labels[idx]
        return self.data[idx]

# 3. Training and Evaluation Function with GPU Support
def train_and_evaluate(model, train_loader, val_loader, device, num_epochs, learning_rate, pos_weight):
    model.to(device)  # Move model to GPU/CPU
    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight]).to(device))
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    for _ in range(num_epochs):
        model.train()
        for data, labels in train_loader:
            data, labels = data.to(device), labels.to(device)  # Move data to GPU/CPU
            outputs = model(data)
            loss = criterion(outputs, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
    
    model.eval()
    true_labels = []
    pred_labels = []
    with torch.no_grad():
        for data, labels in val_loader:
            data, labels = data.to(device), labels.to(device)  # Move data to GPU/CPU
            outputs = model(data)
            predicted = (torch.sigmoid(outputs) >= 0.5).float()
            true_labels.extend(labels.cpu().numpy().flatten())  # Move to CPU for NumPy
            pred_labels.extend(predicted.cpu().numpy().flatten())
    
    return f1_score(true_labels, pred_labels)

# 4. Objective Function for Optuna with GPU Support
def objective(trial, device):
    learning_rate = trial.suggest_float("learning_rate", 1e-4, 1e-2, log=True)
    batch_size = trial.suggest_categorical("batch_size", [16, 32, 64])
    num_layers = trial.suggest_int("num_layers", 1, 3)
    dropout_rate = trial.suggest_float("dropout_rate", 0.0, 0.5)
    layer_sizes = [trial.suggest_int(f"layer_{i}_size", 16, 128, step=16) for i in range(num_layers)]
    num_epochs = trial.suggest_int("num_epochs", 20, 100, step=10)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    model = BinaryClassifier(input_dim, layer_sizes, dropout_rate)
    f1 = train_and_evaluate(model, train_loader, val_loader, device, num_epochs, learning_rate, pos_weight)
    return f1

# 5. Load and Preprocess Data
def load_and_preprocess_data(file_path, target_column, categorical_columns):
    df = pd.read_excel(file_path)
    X = df.drop(columns=[target_column])
    y = df[target_column].values
    
    original_columns = X.columns.tolist()
    
    encoders = {}
    for col in categorical_columns:
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col])
        encoders[col] = le
    
    X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)
    
    scaler = StandardScaler()
    X = scaler.fit_transform(X)
    
    num_normal = (y == 0).sum()
    num_anomaly = (y == 1).sum()
    pos_weight = num_normal / num_anomaly
    
    return X, y, pos_weight, scaler, encoders, original_columns

# 6. Main Function with GPU Support and Saving
def main():
    global train_dataset, val_dataset, input_dim, pos_weight
    
    # Check for GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    # Load data
    file_path = "your_data.xlsx"  # Replace with your file path
    target_column = "label"
    categorical_columns = ["cat1", "cat2"]
    
    X, y, pos_weight, scaler, encoders, original_columns = load_and_preprocess_data(
        file_path, target_column, categorical_columns
    )
    
    # Split data
    X_train, X_temp, y_train, y_temp = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
    )
    
    # Create datasets
    global train_dataset, val_dataset, input_dim
    train_dataset = CustomDataset(X_train, y_train)
    val_dataset = CustomDataset(X_val, y_val)
    test_dataset = CustomDataset(X_test, y_test)
    input_dim = X_train.shape[1]
    
    # Optimize hyperparameters
    study = optuna.create_study(direction="maximize")
    study.optimize(lambda trial: objective(trial, device), n_trials=20)
    
    print("Best Hyperparameters:", study.best_params)
    print("Best F1-Score:", study.best_value)
    
    # Train final model
    best_params = study.best_params
    train_loader = DataLoader(train_dataset, batch_size=best_params["batch_size"], shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=best_params["batch_size"], shuffle=False)
    
    layer_sizes = [best_params[f"layer_{i}_size"] for i in range(best_params["num_layers"])]
    final_model = BinaryClassifier(input_dim, layer_sizes, best_params["dropout_rate"])
    
    f1 = train_and_evaluate(
        final_model, train_loader, val_loader, device,
        best_params["num_epochs"], best_params["learning_rate"], pos_weight
    )
    print(f"Final Model F1-Score on Validation: {f1:.4f}")
    
    # Save the model and preprocessing objects
    torch.save(final_model.state_dict(), "final_model.pth")
    joblib.dump(scaler, "scaler.pkl")
    joblib.dump(encoders, "encoders.pkl")
    joblib.dump(original_columns, "original_columns.pkl")
    joblib.dump(best_params, "best_params.pkl")
    
    print("Model and preprocessing objects saved.")

# 7. Prediction Function with GPU Support
def load_and_predict(new_file_path, model_path="final_model.pth"):
    # Check for GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device for prediction: {device}")
    
    # Load saved objects
    scaler = joblib.load("scaler.pkl")
    encoders = joblib.load("encoders.pkl")
    original_columns = joblib.load("original_columns.pkl")
    best_params = joblib.load("best_params.pkl")
    
    # Load model
    layer_sizes = [best_params[f"layer_{i}_size"] for i in range(best_params["num_layers"])]
    model = BinaryClassifier(input_dim=len(scaler.mean_), layer_sizes=layer_sizes, 
                            dropout_rate=best_params["dropout_rate"])
    model.load_state_dict(torch.load(model_path))
    model.to(device)  # Move model to GPU/CPU
    model.eval()
    
    # Load and preprocess new data
    new_df = pd.read_excel(new_file_path)
    
    missing_cols = set(original_columns) - set(new_df.columns)
    if missing_cols:
        raise ValueError(f"New data is missing columns: {missing_cols}")
    
    X_new = new_df[original_columns]
    
    for col, le in encoders.items():
        if col in X_new.columns:
            X_new[col] = le.transform(X_new[col])
    
    categorical_columns = [col for col in encoders.keys()]
    X_new = pd.get_dummies(X_new, columns=categorical_columns, drop_first=True)
    
    training_columns = scaler.feature_names_in_ if hasattr(scaler, 'feature_names_in_') else X_new.columns
    X_new = X_new.reindex(columns=training_columns, fill_value=0)
    
    X_new = scaler.transform(X_new)
    
    # Predict
    new_dataset = CustomDataset(X_new)
    new_loader = DataLoader(new_dataset, batch_size=32, shuffle=False)
    
    predictions = []
    with torch.no_grad():
        for data in new_loader:
            data = data.to(device)  # Move data to GPU/CPU
            outputs = model(data)
            predicted = (torch.sigmoid(outputs) >= 0.5).float()
            predictions.extend(predicted.cpu().numpy().flatten())  # Move to CPU for NumPy
    
    return np.array(predictions)

# 8. Example Usage
if __name__ == "__main__":
    # Train and save the model
    main()
    
    # Predict on new data
    new_file_path = "new_data.xlsx"  # Replace with your new data file
    predictions = load_and_predict(new_file_path)
    print("Predictions:", predictions)
